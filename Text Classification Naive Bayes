# Text-Classification-Naive-Bayes

###We will use the sparse word count features from the 20 Newsgroups to show how we classify the documents into categories.
###Naive Bayes algorithm is often used is in text classification
from sklearn.datasets import fetch_20newsgroups
data = fetch_20newsgroups()
data.target_names

###select the categories and use the training and testing data set
categories = ['alt.atheism',
 'comp.graphics',
 'comp.os.ms-windows.misc',
 'comp.sys.ibm.pc.hardware',
 'comp.sys.mac.hardware',
 'comp.windows.x',
 'misc.forsale',
 'rec.autos',
 'rec.motorcycles',
 'rec.sport.baseball',
 'rec.sport.hockey',
 'sci.crypt',
 'sci.electronics',
 'sci.med',
 'sci.space',
 'soc.religion.christian',
 'talk.politics.guns',
 'talk.politics.mideast',
 'talk.politics.misc',
 'talk.religion.misc']
train = fetch_20newsgroups(subset='train', categories=categories)
test = fetch_20newsgroups(subset='test', categories=categories)

###to print out your train data(a representative entry from the data)
print(train.data[666])

###Convert the content of each string into a vector of numbers
###We use TF-IDF vectorizer and create a pipeline that attaches it to a multinomial Naive Bayes classifier
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.pipeline import make_pipeline

###With this pipeline, we can apply the model to the training data and predict labels for the test data
model = make_pipeline(TfidfVectorizer(), MultinomialNB())
model.fit(train.data, train.target)
labels = model.predict(test.data)

###import seaborn: statistical data visualization
%matplotlib inline
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns; sns.set()

###Now that we have predicted the labels for the test data, we can evaluate them to learn about the performance of the estimator
from sklearn.metrics import confusion_matrix
mat = confusion_matrix(test.target, labels)
sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False,
            xticklabels=train.target_names, yticklabels=train.target_names)
plt.xlabel('correct label')
plt.ylabel('estimated label');

###measure the accuracy
from sklearn.metrics import accuracy_score
print ("Accuracy score is ", accuracy_score(labels, test.target))

###We now have the tools to determine the category for any string, using the predict() method of this pipeline
###A quick utility function that will return the prediction for a single string
def predict_category(s, train=train, model=model):
    pred = model.predict([s])
    return train.target_names[pred[0]]

###Now use predict_category(' ') to let to machine to do the text classification
#TEST 1
predict_category('sending a payload to the ISS')
#TEST 2
predict_category('discussing atheism')
#TEST 3
predict_category('Space')
#TEST 4
predict_category('motor')
#TEST 5
predict_category('motorcycle')
